{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee77cb4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### ABB\n",
    "- PCA: Principal Component Analysis: giarm chiều dữ liệu (lấy vector riêng, giá trị riêng, rồi chuyển đổi dữ liệu theo các trị riêng max)\n",
    "    - Thiết lập các trục mới dựa trên dữ liệu ban đầu để có đc các phương sai max (biểu diễn )\n",
    "    - Lúc này thông tin của các quan sát sau này đc chuyển thành giá trị riêng biểu diễn phương sai của các thành phần chính Pricipal Component (PC)\n",
    "    - Các PC1, PC2... giải thích cho % của các biến động\n",
    "    - Các PC là những đường xu hướng mà trên đó các quan sát thể hiện phương sai/sự biến động lớn nhất\n",
    "    - thương các PC đầu sẽ thể hiện tỉ lệ lớn các biến động -> có thể giảm chiều dữ liệu\n",
    "- OLS: Ordinary Least Squares (OLS): hồi quy tuyến tính trong thư viện statsmodel.api import sm (statsmodel) \n",
    "- CI: Confidence Interval: Khoảng tin cậy (vd: chọn độ tin cậy là 95%, thì cứ khi lấy 1 mẫu bất kỳ thì có xác suất 95% \"giá trị trung bình\" của mẫu rơi vào khoảng CI). Khoảng tin cậy có dạng [a, b]\n",
    "- SD: standard Deviation \n",
    "- SE: Standard Error\n",
    "- dof: degree of freedom: bậc tự do: df = n-1 (n: số lượng mẫu)\n",
    "    - khi bậc tự do nhỏ => phân phối mẫu thấp và cách đường ox xa hơn \n",
    "    - khi bậc tự do càng cao => phân phối mẫu càng giống phân phối chuẩn \n",
    "    - Khi bậc tự do = 30, phân phối này gần tiệm cận phân phối chuẩn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f02156",
   "metadata": {},
   "source": [
    "# Tham số thống kê\n",
    "### 1. StandardScaler: \n",
    "chuyển dữ liệu về dạng chuẩn với mean = 0,standard deviation = 1\n",
    "<br>\n",
    "Quy về cùng là độ lệch so với mean của mỗi biến -> dễ so sánh và tính toán\n",
    "<br>\n",
    "$$\n",
    "x' = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "### 2. R2 (Coefficient of Determination): \n",
    "*Cho biết mô hình giải thích được bao nhiêu % phương sai của Y.*\n",
    "- Giá trị trong [0, 1]:\n",
    "    - Gần 1 → mô hình rất tốt.\n",
    "    - Gần 0 → mô hình kém.\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "- Trong đó:\n",
    "    - \\( y_i \\): giá trị thực tế  \n",
    "    - \\( $\\hat{y}_i$ \\): giá trị dự đoán  \n",
    "    - \\( $\\bar{y}$ \\): giá trị trung bình của \\( y \\)\n",
    "- from sklearn.metrics import r2_score\n",
    "### 3. Adjusted R²: \n",
    "**Dùng khi có nhiều biến độc lập, giúp tránh việc thêm biến không cần thiết làm R² tăng giả tạo.** \n",
    "$$\n",
    "R^2_{adj} = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right)\n",
    "$$\n",
    "- R2: Hệ số xác định (Coefficient of Determination)\n",
    "- n: Số lượng quan sát (sample size)\n",
    "- k: Số biến độc lập (number of predictors)\n",
    "\n",
    "- (1) Thông thường, thêm càng nhiều biến thì độ chính xác của mô hình càng tăng.\n",
    "- (2) Tuy nhiên, khi cung cấp những biến không liên quan thì có thể gây nhiễu kết quả -> vì vậy chúng ta xem xét R^2 hiệu chỉnh\n",
    "\n",
    "\n",
    "### 4. p-value: kiểm định xem hệ số có ý nghĩa thống kê không.\n",
    "(giả định là H0 (null hypothesis, thường ngược với giải thuyết đang muốn chứng minh), thu thập dữ liệu D, xác suất của D nếu H0 đúng: p = P(D|H0))\n",
    "- Nếu p-value < 0.05 → hệ số có ý nghĩa (ảnh hưởng thật). \n",
    "    - Nếu H0 đúng thì dữ liệu D ko thể có \n",
    "    - Nhưng dữ liệu xảy ra\n",
    "    - Do đó giả thuyết vô hiệu là ko đúng \n",
    "    - (xác suất của dữ liệu xảy ra với H0 nhỏ -> phủ định H0 -> điều ngc lại đúng: X, Y liên quan)\n",
    "- Nếu p-value > 0.05 → có thể loại bỏ biến đó: chưa đủ dữ liệu khẳng định liên quan X, Y.\n",
    "VD: H0: ko có mối tương quan giữa X và Y -> hệ số tương quan = 0\n",
    "\n",
    "### 5.0. Độ lệch chuẩn (Standard Deviation - SD)\n",
    "- đo mức độ phân tán của các giá trị dữ liệu quanh giá trị trung bình (mean).\n",
    "$$\n",
    "s = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n - 1}}\n",
    "$$\n",
    "### 5. Sai số chuẩn của hệ số (Standard Error - SE): Cho biết độ tin cậy của ước lượng hệ số.\n",
    "- Độ lệch chuẩn nhỏ → hệ số được ước lượng ổn định.\n",
    "- cho biết nếu lấy nhiều mẫu khác nhau, trung bình của các mẫu đó sẽ dao động quanh giá trị trung bình tổng thể bao nhiêu. (Khoảng cách giữa trung bình của một mẫu so với trung bình của tổng thể)\n",
    "$$\n",
    "SE = \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "### 6. Kiểm tra giả định của mô hình\n",
    "- Phân phối phần dư (residuals): Phải gần như phân phối chuẩn\n",
    "- Độ tự tương quan (Durbin–Watson test): Residuals không nên có quan hệ nối tiếp\n",
    "- Độ đồng nhất phương sai (Homoscedasticity):\tPhương sai của residuals nên ổn định\n",
    "- Đa cộng tuyến (VIF):\tKhông nên có biến X nào tương quan quá cao với biến khác\n",
    "\n",
    "### 7. t, \n",
    "\n",
    "- Giả định hệ số của biến A = 0 (A ko ảnh hưởng tới biến phụ thuộc y) => nếu p(t) < 0.05 => có ý nghĩa thống kê => giải thuyết H0 sai => hệ số của biến A phải khác ko\n",
    "=> trong bảng summary() của statsmodels thì loại dần các biến có giá trị p(t) lớn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e1ce1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Overfiting\n",
    "1. Chia dữ liệu thành Train / Validation / Test \n",
    "- Nếu chênh lệch giữa hai kết quả này lớn → overfitting.\n",
    "2. Dùng biểu đồ “learning curves”\n",
    "- Vẽ train loss và validation loss theo số epoch (hoặc iterations):\n",
    "3. Cross-validation\n",
    "- Dùng k-fold cross-validation để xem mô hình có ổn định hay không. Nếu kết quả dao động lớn giữa các fold → khả năng cao bị overfitting.\n",
    "\n",
    "# cách giảm \n",
    "- Giảm độ phức tạp mô hình (ít tham số hơn, bỏ bớt lớp, giảm feature, v.v.)\n",
    "- Regularization (L1, L2, Dropout, Early stopping)\n",
    "- Tăng dữ liệu huấn luyện (data augmentation, thu thập thêm dữ liệu)\n",
    "- Cross-validation để đánh giá mô hình khách quan hơn\n",
    "- Early stopping – dừng huấn luyện khi validation loss không còn cải thiện\n",
    "\n",
    "# Tuning (Hyperparameter tuning): điều chỉnh hyperparamaters của mô hình để đạt hiệu suất tốt nhất trên dữ liệu. Trong mô hình có 2 loại tham số:\n",
    "1. Parameter (tham số): trọng số (weights) trong mạng neural, hay hệ số hồi quy (β) --> mô hình tự học từ dữ liệu\n",
    "2. Hyperparameter: (siêu tham số), vd: learning rate, số lớp, độ sâu cây, batch size, regularization strength... Là quá trình chọn thủ công trước khi huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20afc0de",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### 1. DecisionTreeClassifier\n",
    "- feature_importances_: Mức độ quan trọng của từng đặc trưng\n",
    "- n_features_in_: Số đặc trưng đầu vào\n",
    "### 2. RandomForestClassifier\n",
    "- estimators_: Danh sách cây con (decision trees)\n",
    "- feature_importances_: Tầm quan trọng của biến\n",
    "\n",
    "### 3. Linear Regression\n",
    "\n",
    "- coef_: hệ số góc, hệ số hồi quy (biểu diễn sự thay đổi mạnh hay yếu của y theo x) (kulmakerroin: slope, kerroin> factor)\n",
    "- intercept_: hệ số chặn (y cắt với y = 0 tại điểm nào)\n",
    "- n_features_in_: Số lượng đặc trưng đầu vào\n",
    "- feature_names_in_: Tên các cột đầu vào\n",
    "- classes_: Danh sách nhãn trong bài toán phân loại\n",
    "\n",
    "-- làm sạch dữ liệu\n",
    "- summary() của statsmodels\n",
    "    - chọn loại bỏ các giá trị p(t) > 0.05 (ngưỡng chấp nhận là 5% hoặc 10% ...)\n",
    "    - R2  <ins>càng lớn càng tốt</ins> (Đo độ phù hợp của mô hình, đã điều chỉnh cho số biến.)\n",
    "    - AIC <ins>càng nhỏ càng tốt</ins> (Akaike Information Criterion) (Đánh giá cân bằng giữa độ phù hợp và độ phức tạp.)\n",
    "    - BIC <ins>càng nhỏ càng tốt</ins> (Bayesian Information Criterion) (Giống AIC nhưng phạt nặng hơn mô hình phức tạp.)\n",
    "\n",
    "### 4. LogisticRegression\n",
    "- coef_: Hệ số của mỗi biến\n",
    "- intercept_: Hệ số chặn\n",
    "- classes_: Danh sách nhãn phân loại\n",
    "- n_iter_: Số vòng lặp thực tế khi huấn luyện\n",
    "\n",
    "### 5. KMeans\n",
    "- cluster_centers_: Tọa độ các tâm cụm (centroid)\n",
    "- labels_: Cụm mà mỗi điểm dữ liệu thuộc về\n",
    "- inertia_: Tổng bình phương khoảng cách trong cụm (WCSS)\n",
    "### 6. SVM (Support Vector Machine)\n",
    "- support_vectors_:\tVector hỗ trợ\n",
    "- support_:\tChỉ số (index) của các vector hỗ trợ\n",
    "- n_support_:\tSố vector hỗ trợ trong mỗi lớp\n",
    "\n",
    "### 7. PCA (Principal Component Analysis)\n",
    "- components_: Vector thành phần chính (eigenvectors)\n",
    "- explained_variance_\tPhương sai mà mỗi thành phần chính giải thích\n",
    "- explained_variance_ratio_\tTỷ lệ % phương sai giải thích\n",
    "- singular_values_\tGiá trị kỳ dị (SVD)\n",
    "\n",
    "### 8. StandardScaler\n",
    "- mean_:\tGiá trị trung bình từng cột\n",
    "- scale_:\tHệ số chia (độ lệch chuẩn hoặc biên độ)\n",
    "- var_:\tPhương sai của từng đặc trưng\n",
    "\n",
    "### 9. LabelEncoder / OneHotEncoder\n",
    "- classes_:\tTên các nhãn hoặc giá trị gốc\n",
    "- categories_:\tCác giá trị duy nhất trong từng cột (OneHotEncoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03a022",
   "metadata": {},
   "source": [
    "1. Hist\n",
    "- kiểm tra xem dữ liệu có tuân theo phân phối chuẩn ko \n",
    "2. Q-Q plot\n",
    "- Biểu thị độ tương quan giưa các quan sát trong phân bố mẫu và phân bố lý thuyêt\n",
    "- Nếu mẫu có phân phối chuẩn thì các quan sát nằm trên một đường thẳng\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
